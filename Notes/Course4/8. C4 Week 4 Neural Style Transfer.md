### Neural Style Transfer
- Neural style transfer is application of convolutional neural networks (CNNs) that allows us to create unique artworks by combining the content of one image with the style of another.
- To implement neural style transfer, we look at the features extracted by CNNs at various layers. Both shallow and deep layers of a CNN play crucial roles in this process.
 - C: Content image
 - S: Style image
 - G: Generated image
- The goal is to create a new image G that looks like the content image C but in the style of the style image S.
#### What are deep Convulutional Networks Learning?
- To understand what different layers of a ConvNet are learning, we can visualize the hidden units' activations. 
- Layer 1 Hidden Units: For a hidden unit in the first layer, find the image patches from the training set that maximize the unit's activation. Since layer 1 units see only a small portion of the image, visualize these small image patches.
- Layer 2 Hidden Units:Repeat the process for layer 2 units.Layer 2 units see larger portions of the image and start detecting more complex shapes and patterns.Example: A hidden unit might be activated by vertical textures or specific rounded shapes.
- Deeper Layers: As we move to deeper layers, hidden units see even larger portions of the image and detect more complex patterns.
    - Layer 3: Detects combinations of edges and simple textures.
    - Layer 4: Starts recognizing parts of objects, like dog legs or bird features.
    - Layer 5: Detects complete objects or complex textures, such as dogs, keyboards, or flowers.

![nst learn](https://github.com/user-attachments/assets/052c6f16-f917-43df-87bf-453ccf1feabb)

#### Neural Style Transfer Cost Function:
- Cost Function J(G) consists fo two separate cost values :

  - Content Cost:
     -  It measures how well G resembles the image C.
     - Formula :`J_content(C,G) = 1/2 * ∑(a[l][C] - a[l][G])^2`
     - `a[l][C]` and `a[l][G]`are activations of layer having the content image and the generated image respectively.
     - ![content cost](https://github.com/user-attachments/assets/2581fc29-8403-4e2a-b7f7-49dfc7c3bad1)

  - Style Cost:
    - It measures how well G matches the style of S. It ensures that G captures style of S well.
    - Formula: `J_style(C,G) = ∑∑(S^[L](k, k') - G^[L](k, k'))^2`
    - ![style cost](https://github.com/user-attachments/assets/b14f906d-98e0-4630-86ab-02ec3b3b7308)

- Cost Function J(G):
- Formula : `J(G) = α J_content(C, G) + β J_style(S, G)`
  - We use weights α and β to balance the importance of content and style in the cost function.
- Intuition:
  - We start with a random image by initializing G with random pixels.  
  - We then adjust G using gradient descent to minimize cost function J(G)`.  
  - Change G based on how it affects J(G).

![nst cost 2](https://github.com/user-attachments/assets/32fac876-d8f4-45d3-be9e-94579a67b62d)

![nst cost](https://github.com/user-attachments/assets/96c83d10-b6c8-4e06-80db-91bd8ae11699)

#### Style Matrix:
- The style matrix captures the correlation between different channels' activations in a given layer L of a neural network.
- It is an nc×nc matrix, where nc is the number of channels.
- Each element in the style matrix, denoted as `G_l(k, k)`, measures how correlated the activations in channel k are with the activations in channel k'. The values of k and k' range from 1 to nc.
- Computation:
  - For each pair of channels k and k′ we sum the products of activations at all spatial positions (i,j).
  - Formula: `G^L(k, k') = ∑∑ activation(i, j, k) * activation(i, j, k')`
  - This captures how features in one channel relate to features in another, providing a measure of the image's style.

![style matrix](https://github.com/user-attachments/assets/33f641c3-50e0-4903-8e89-0698222dfa1f)
