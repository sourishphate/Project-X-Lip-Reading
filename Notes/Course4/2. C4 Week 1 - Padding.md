### Padding in Convolutional Neural Networks (CNNs):
- Padding is a technique used in CNNs to preserve the dimensions of the input image after applying a convolution operation.
- Problems during convolution:
  - Shrinkage of Image Size:
     - When you convolve a 6x6 image with a 3x3 filter, you get a 4x4 output.
     - This happens because the filter can only fit into a limited number of positions in the original image.
     - `For an n×n image convolved with an f×f filter, the output size is (n−f+1)×(n−f+1).`

  - Loss of Edge Pixel Information:
     - Pixels at the corners and edges of the image are used less frequently in the output.
     - Central pixels are included in more filter regions, leading to more influence on the output.
     - This causes a loss of information from the edges, which is undesirable for many applications.

- To solve the issues of image shrinkage and edge information loss, padding is used. Padding adds extra pixels around the border of the image.
- General Formula:
  - `For an n×n image, with padding p and anf×f filter, the output size is (n+2p−f+1)×(n+2p−f+1).`

   ![padding](https://github.com/user-attachments/assets/fbef5553-334f-4e02-a68e-b59469d61d32)

- Types of Padding
 - Valid Convolution:
   - No padding is applied.
   - Output size is (n−f+1)×(n−f+1).
 - Same Convolution:
   - Padding is applied to keep the output size the same as the input size.
   - For a filter of size f, the padding p required is (f−1)/2 when f is odd.
   - Ensures the output size is n×n.

   ![padding 2](https://github.com/user-attachments/assets/b6118914-b95c-4aa9-be9f-03f39206277a)

- Use Odd-Sized Filters:
  - Odd-sized filters, such as 3x3 or 5x5, have a central pixel, making it easier to define and understand the filter's position.
  - Padding is more naturally symmetric with odd-sized filters.

### Strided Convolutions in Convolutional Neural Networks (CNNs):
- Strided convolutions are a powerful tool in CNNs for reducing the spatial dimensions of the input while maintaining important features.
- Consider a 7x7 input image convolved with a 3x3 filter using a stride of 2.
- Instead of moving the filter one pixel at a time, it moves two pixels at a time.
- How It Works:
  - Start with a 7x7 image and a 3x3 filter.
  - Place the filter at the top-left corner of the image.
  - Move it over two pixels to the right, then do the same thing for the next row, moving down by two pixels each time.
  - The result is a smaller, 3x3 output image.

- Why Use Strided Convolutions?
  - They make the image or feature map smaller, which reduces the amount of data and computation needed.
  - This helps in creating more efficient neural networks.

- Formula:
 - `Output Size = [(N+2P-F)/S]+1`
 - `N` is the size of the input (height or width).
 - `F` is the size of the filter.
 - `P` is the padding.
 - `S` is the stride.


 ![stride cn](https://github.com/user-attachments/assets/e4b07c79-efce-4450-8cec-16f28cc3d0fb)