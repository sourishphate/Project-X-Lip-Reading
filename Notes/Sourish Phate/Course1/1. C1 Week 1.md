# Neural Networks-
- Neural networks are a class of machine learning models inspired by the human brain. They consist of interconnected layers of nodes (neurons) that process data and learn to recognize patterns.

- They are composed of layers of interconnected nodes, or neurons, each performing simple computations to solve complex tasks.

## Basic Structure-
- Input Layer: The first layer that receives the input data.
- Hidden Layers: Layers between the input and output layers where computations are performed. There can be multiple hidden layers.
- Output Layer: The final layer that produces the output.

## Supervised Learning-
- Structured data: It is data that has context and meaning and is represented in a proper structured format to find the output.

For example in the house price prediction we use different parameters such as locality ,transport, area etc as structured data to find the output that is the price of the house.
- Unstructured Data:This data is not structured like above and has to be analysed to find the context.For example a raw audio file or a picture.

## Types of Neural Networks-
- Feedforward Neural Networks (FNN): Data flows in one direction from input to output.
- Convolutional Neural Networks (CNN): Specialized for processing grid-like data such as images.
- Recurrent Neural Networks (RNN): Designed for sequential data, where outputs are dependent on previous computations.
- Long Short-Term Memory (LSTM): A type of RNN that can capture long-term dependencies in sequential data.

### Why is Deep Learning taking off?
- Scale drives deep learning progress.
- When there is large amounts of data available we can train larger neural networks which will perform better than other aproaches.
