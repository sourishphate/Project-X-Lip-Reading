### One Layered Convolutional network
- We start with a 3D input (e.g., an image with height, width, and depth). We convolve this input with multiple filters (kernels) to produce 2D output image.
- We can use multiple filters to detect different features (e.g., edges, textures).
- For each filter, you add a bias term (a real number) to each element in the feature map.The same bias is added to every value in the 4x4 output image.
- After adding the bias, we apply a non-linearity (e.g., ReLU) to each element in the feature map.
This introduces non-linearity to the model, enabling it to learn more complex patterns.
- We stack the resulting feature maps along the depth dimension. For example, convolving with two filters would result in a 4x4x2 output volume.


![one layer](https://github.com/user-attachments/assets/45ce0f89-242b-4797-8b0c-fba0f40ed5c3)

#### Notation:
- `f[l] = filter size`
- `p[l] = padding`
- `s[l] = stride`
- `nc[l] = number of filters`
- `Each filter: f[l] * f[l] * nc[l-1]`
- `Activation: a[l] = nh[l] * nw[l] * nc[l]`
- `Weights: f[l] * f[l] * nc[l-1] * nc[l]`
- `Bias: nc[l] - (1,1,1,nc[l])`
- `n[l] = ((n[l-1] + 2p[l] - f[l]) / s[l] ) + 1`
- `Input = nh[l-1] * nw[l-1] * nc[l-1]`
- `Output = nh[l] * nw[l] * nc[l]`

```
- Layer Parameters:
  - If you have 10 filters, each 3x3x3, then each filter has 27 parameters plus 1 bias, making 28 parameters per filter. With 10 filters, you have 28×10=280 parameters.
 - The number of parameters remains constant regardless of the input size. This characteristic helps in reducing the risk of overfitting.
``` 

#### Simple Convolutional Network Example:

![cnn eg](https://github.com/user-attachments/assets/f3e357b7-e63b-45aa-9924-b0a2fd7694fa)

### Pooling Layers:
- Max Pooling:
  - Max pooling is a type of pooling operation where you take the maximum value from a defined region of the input and this value is representative of that region when the input is being processed in the CNN.
  - This reduces the dimensions of the input while keeping the most important information.

- Example:
  - Suppose we have a 4×4 input and you want to apply max pooling with a 2×2 filter and a stride of 2.
  - The input is divided into 2×2 regions. For each region, the maximum value is taken to form the output.

![max pooling](https://github.com/user-attachments/assets/2f9c38bc-d043-4c8d-b62b-8a18beab9f61)

- Average Pooling:
  - Average pooling takes the average value from a defined region of the input instead of the maximum value.
  - Average pooling helps in reducing the impact of outliers or extreme values in the input data.
  - It can be useful in certain situations, such as reducing the dimensions of a feature map in deeper layers of the network.
  - Example: For a 2×2 region, the average value is computed and used as the output.

![avg pooling](https://github.com/user-attachments/assets/8ff31325-463f-4aec-b64e-6081cd6fa8f4)

```
Hyperparameters:
Filter Size (F): The size of the region over which pooling is applied. 
Stride (S): The step size by which the filter moves across the input. 
```

###  Convolution Neural Network Example:
- **Input:**
    - We start with an image that is 32 x 32 pixels and has 3 color channels (RGB).

- **Convolutional Layer:**
    - We apply a filter of size `5 x 5` to the input image. This filter helps us extract features from the image.
    - We use 6 filters in this layer, so the output becomes `28 x 28 x 6`

- **Pooling Layer:**
    - We apply a pooling operation to reduce the size of the output from the previous layer.
    - In this case, we use max pooling with a filter size of `2 x 2` and a stride of 2.
    - This reduces the output size to `14 x 14 x 6`

- **Repeat:**
    - We can repeat the convolutional and pooling layers to further extract features and reduce the size of the output.

- **Fully Connected Layer:**
    - Finally, we connect the output of the previous layers to a fully connected layer, which helps us classify the image into one of the 10 possible digits (0 to 9).

![nn eg](https://github.com/user-attachments/assets/5ce45430-6ebe-4d09-800c-384d0fd0546c)

![nn eg2](https://github.com/user-attachments/assets/b755f326-c043-4721-8a89-e485450395e3)

### Why convolution?
- Parameter Sharing:
  - A feature detector (e.g., edge detector) is useful across different parts of the image.
  - The same parameters (filter weights) are reused for different positions in the image.
 - Sparsity of Connections:
  - Each filter is applied to a local region of the input, reducing the number of parameters compared to fully connected layers.

![why conv](https://github.com/user-attachments/assets/daa77ab6-c270-49eb-8693-8664ee6257b6)
