## Semantic Segmentation with U-net:
- Semantic segmentation is a computer vision algorithm that helps us understand and label every single pixel in an image. It goes beyond just detecting objects or drawing bounding boxes around them.
- Semantic segmentation labels each pixel in an image, determining if it belongs to an object and which object it is. 

#### Per-Pixel Class Label:
- Per-pixel class labeling is a technique used in semantic segmentation where each pixel in an image is assigned a specific class label. 
- This allows for a detailed and precise classification of every part of the image, rather than just identifying objects and their locations.

![per pixel](https://github.com/user-attachments/assets/51142a99-7384-4313-9085-37f0808e607a)

### Transpose Convolution:
- Key Parameters include Filter Size (f) , Padding (p) and Stride (s).
- Initialize the Output Grid:
  - Begin with an empty output grid initialized with zeros. The size of the output grid depends on the - input size, filter size, padding, and stride.
- Place the Filter on the Output Grid:
  - Imagine the filter as a small window that you will place on the output grid.
  - The filter will be moved across the output grid in steps defined by the stride.
- Multiply and Add:
  - For each position of the filter on the output grid, multiply each value in the filter with the corresponding value in the input grid.
  - Add the results to the respective positions in the output grid.
- Handle Overlaps:
  - If the filter placements overlap on the output grid, sum the overlapping values.

![transose conv](https://github.com/user-attachments/assets/c190bf69-6298-440e-a2cd-0ea63e2e73f2)

### U-Net :
-The U-Net architecture is a neural network designed for semantic segmentation tasks, where the goal is to classify each pixel in an image.
#### U-Net Architecture:
- Input Image:
   - The input to the U-Net is an image, represented as a grid of pixels with three color channels (red, green, and blue).

- Convolutional Layers:
   - The U-Net starts with a series of convolutional layers where we use filters to extract important features from the image.
   - These layers detect patterns like edges, textures, and more complex structures as we move through the network.

- Activation Functions:
   - After each convolutional layer, activation functions are applied. These introduce non-linearity, making the network capable of learning more complex patterns.

- Max Pooling:
   - Max pooling layers follow the convolutional layers to reduce the size of the image while making sure that important features are not lost.
   - This process reduces the size of the image while preserving important features.

-  Transpose Convolutions:
   - After the first half of the network (the down sizing part), the U-Net starts using transpose convolutional layers.
   - These layers help to increase the size of the image again, upscaling the compressed image features.

- Skip Connections:
   - The U-Net includes skip connections, which copy activations from earlier layers when we were reducing the size of the image and combine them with the current layer's activations.
   - This helps to preserve important features that might have been lost during downscaling and improves the network's performance.

- Output Segmentation:
   - Finally, a one-by-one convolutional layer is used to map the output to a segmentation map.
   - This map assigns each pixel in the image to a specific class or category, effectively labeling the entire image.

![unet](https://github.com/user-attachments/assets/c6baf430-2293-4468-88e6-539530c8c434)
