### Normalizing Inputs:
- Normalizing inputs means all  processing the input features such that they have similar scaling.This helps in speeding up training.
- It involves two steps:
  - The first step is subtracting the mean `μ` from each training example.This shifts the training set so it has a mean of zero.
  - The next step involves calculating the standard variance `σ^2` and dividing each training example with the standard deviation `σ`.This scales the training set so that each feature has a variance of one.

![normalize input](https://github.com/user-attachments/assets/adac1149-6958-4869-a7c8-7005df83f0a2)

##### Why normalize inputs?
- Normalization helps because the cost function J is easier to optimize when the input features are on a similar scale.
- Without normalization, if the input features have different scales ,the cost function can be very elongated, making it harder for gradient descent to find the minimum since we will have a slow learning rate  i.e more steps.
- With normalized features, the cost function is more spherical or symmetrical, allowing gradient descent to reach the minimum more quickly.

![why normalize](https://github.com/user-attachments/assets/2f1ef8dc-e752-4f28-9752-0c5e128a9884)

### Vanishing/ Exploding Gradient Problem:
- The general idea is that when we are training very deep neural networks sometimes the dervatiives (slopes) can get very big or very small. This makes training the network difficult.

- When the weight matrix 'W' for each layer is initialized to be slightly larger than the identity matrix, the output of the network grows exponentially with the number of layers. This is known as the problem of exploding gradients.If gradients are very large, they can cause numerical instability and make it difficult for the network to to learn and make gradient descent very slow.

- When the weight matrix 'W' for each layer is initialized to be slightly smaller than the identity matrix, the output of the network decreases exponentially with the number of layers. This is known as the problem of vanishing gradients.This means activations and gradients decrease exponentially, making it hard for the network to learn.

To deal with this it is important to be careful when initializing weights in each layer.

![vanishing gradient](https://github.com/user-attachments/assets/6163d9db-e49a-4391-9764-6e28e20c3d3d)

### Weight Initialization:
- When we are training very deep neural networks sometimes the dervatives (slopes) can get very big or very small. This makes training the network difficult.This causes the anishing/ Exploding Gradient Problem.
- One common approach is to randomly initialize the weights using a Gaussian distribution. 
  - If we have a neuron with 4 input features, we can set the variance of the weights to be `1/4` 
  - With the tanh activation function, it has been found that setting the variance of the weights to `1/n`
  - If we're using a ReLU activation function, it's even better to set the variance to be `2/n`, where n is the number of input features.

  ![weight initial](https://github.com/user-attachments/assets/c6b3594d-e924-4d23-87b0-0da3b0946f3d)

### Numerical Approximations of Gradients:

- Use the two-sided difference method to approximate the gradient:
 - Formula : `g(θ) ≈ (f(θ + ε) - f(θ - ε)) / (2 * ε)`.
 - This method is more accurate than one-sided difference, which uses only θ+ϵ or θ−ϵ.
 - The two-sided method provides a better estimate because its error decreases with ϵ^2 , making it more reliable.

 ![gradient check](https://github.com/user-attachments/assets/308191dd-d609-4cbd-a0a2-d5d3f2aa5cb3)

## Gradient Checking:
- Gradient checking helps ensure that the gradients computed by your backpropagation implementation are correct. It does this by comparing them to numerically approximated gradients.

- Reshape and concatenate: 
  - The first step involves reshaping the parameters i.e the weights (W) and biases (B). We convert these to vectors and then concatenate these into a big vector `'θ'`.
  - We perform the same operation on the dervatives of W  and B  and store them in a vector `dθ`.
  - Cost Function:
  - So instead of the cost function J being a function of the weights and biases it will be a function of θ.
- Approximating the derivatives: 
  - We want to check if the derivatives of J with respect to theta (dθ) are correct. To do this,we implement  loop and then we compute an approximation of dθ for each component of θ using a two-sided difference as defined above.
- Comparing the vectors: 
  - We compare the computed dθ approx with the actual derivative dθ. If they are approximately equal, it means our derivative approximation is likely correct.

  ![grad check 2](https://github.com/user-attachments/assets/dac6bd10-0fa8-4749-8a03-54a16296ccc3)

#### Gradient Checking Implementation notes:
  - Don't use in training - only to debug
  - If algorithm fails grad check, look at components to try to identify bug.
  - Remember regularization.
  - Doesn't work with dropout.
  - Run at ramdom initialization, perhaps again after some training.








