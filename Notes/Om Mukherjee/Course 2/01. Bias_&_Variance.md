
### Train/ dev/ tests sets

- Splitting up the dataset into training, development, and test sets will make the process more efficient.
- Nowdays generally it is splitted into 98% training set, 1% dev set and 1% test set.
- Training algorithms on training sets, development sets to see which model works best and the best model is then evaluated using test sets.
- Make sure train and test sets comes from same distribution
- It okay not having a test set (only dev set)

### Bias and Variance

- Bias refers to how well our algorithm fits the training data.
- If our classifier has high bias, it means it is not able to capture the complexity of the data and underfits the training set.

- Variance refers to how well our algorithm generalizes to new, unseen data.
- If our classifier has high variance, it means it is too flexible and overfits the training set.

![bias variance](https://github.com/user-attachments/assets/dd304ead-4bca-44c3-b09a-b330ba6b3b94)

|                           | Train set error | Dev set error |
| ------------------------- | --------------- | ------------- |
| High variance             | 1%              | 11%           |
| High bias                 | 15%             | 16%           |
| High bias & high variance | 15%             | 30%           |
| Low bias & Low variance   | 0.5%            | 1%            |

    1. High bias
        - Increase the complexity of the network by adding more hidden layers or units
        - Train the network for a longer time

    2. High Variance
        - Get more data (if possible)
        - Use regularization techniques to reduce overfitting

#### Making good choices

- Applied ML is a higly iterative processs \
   idea -> code -> experiment (repeat)
- Hyperparameter (layers, hidden units, learning rates, activation funtion) are adjusted after going through the above cycle multiple times to make a good choice.